{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 4745574,
     "sourceType": "datasetVersion",
     "datasetId": 2746265
    },
    {
     "sourceId": 114262421,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import cv2\nimport os\nimport glob",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T17:16:13.908814Z",
     "start_time": "2024-10-10T17:16:13.676245Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "def process_satellite_images(source_dir, output_dir, max_size=1024):\n    \"\"\"\n    Process satellite images from source directory and save them to output directory.\n    \n    Args:\n    source_dir (str): Path to the source directory containing satellite image data.\n    output_dir (str): Path to the output directory where processed images will be saved.\n    max_size (int): Maximum dimension (width or height) of the output images.\n    \"\"\"\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    # Iterate through folders in the source directory\n    for folder in os.listdir(source_dir):\n        tci_image_path = os.path.join(source_dir, folder, \"*.SAFE/GRANULE/*/IMG_DATA/*_TCI.jp2\")\n        \n        # Find all TCI image files\n        tci_image_files = glob.glob(tci_image_path)\n        \n        for image_file in tci_image_files:\n            # Extract subdirectory name from the image file path\n            subdirectory_name = image_file.split('/')[-3]\n            dest_subdirectory = os.path.join(output_dir, subdirectory_name)\n            \n            # Create subdirectory in the output directory if it doesn't exist\n            if not os.path.exists(dest_subdirectory):\n                os.makedirs(dest_subdirectory)\n                \n            # Preprocess the image\n            processed_image = resize_and_convert_to_grayscale(image_file, max_size)\n            output_image_path = os.path.join(dest_subdirectory, os.path.basename(image_file).replace('.jp2', '.jpg'))\n            \n            # Save the processed image as JPEG\n            cv2.imwrite(output_image_path, processed_image, [int(cv2.IMWRITE_JPEG_QUALITY), 90])",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def resize_and_convert_to_grayscale(image_path, max_size=1024):\n    \"\"\"\n    Load an image, convert it to grayscale, and resize it while maintaining aspect ratio.\n    \n    Args:\n    image_path (str): Path to the input image file.\n    max_size (int): Maximum dimension (width or height) of the output image.\n    \n    Returns:\n    numpy.ndarray: Processed grayscale image.\n    \"\"\"\n    # Read the image in grayscale mode\n    img = cv2.imread(image_path, 0)\n    height, width = img.shape\n    \n    scale = max_size / max(height, width)\n    \n    # Resize the image\n    resized_img = cv2.resize(img, (int(width * scale), int(height * scale)))\n    return resized_img",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "process_satellite_images('/kaggle/input/deforestation-in-ukraine/', 'processed_dataset')",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import zipfile\n\ndef create_zip_from_directory(directory_path, zip_file_path):\n    \"\"\"\n    Create a ZIP file from the specified directory.\n    \n    Parameters:\n    - directory_path: Path to the directory to be zipped.\n    - zip_file_path: Path for the output ZIP file.\n    \"\"\"\n    with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n        # Walk through the directory and add files to the zip file\n        for foldername, subfolders, filenames in os.walk(directory_path):\n            for filename in filenames:\n                file_path = os.path.join(foldername, filename)\n                zip_file.write(file_path, os.path.relpath(file_path, directory_path))",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "zip_file_path = '/kaggle/working/processed_dataset.zip'\n",
    "create_zip_from_directory('/kaggle/working/processed_dataset', zip_file_path)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T17:16:46.571326Z",
     "start_time": "2024-10-10T17:16:41.297543Z"
    }
   },
   "cell_type": "code",
   "source": "pip freeze > requirements.txt",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
